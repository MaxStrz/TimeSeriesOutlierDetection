{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b547a7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.HBOSagg\n",
    "from models.HBOSagg import HBOSAgg, HBOS_dynamic_bins\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0aca4958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module models.HBOSagg in models:\n",
      "\n",
      "NAME\n",
      "    models.HBOSagg\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        HBOSAgg\n",
      "    pyod.models.hbos.HBOS(pyod.models.base.BaseDetector)\n",
      "        HBOS_dynamic_bins\n",
      "    \n",
      "    class HBOSAgg(builtins.object)\n",
      "     |  HBOSAgg(instances: int = 100, dynamic_bins: bool = True) -> None\n",
      "     |  \n",
      "     |  Histogram-Based Outlier Score Aggregator (HBOSAgg) takes the mean of the \n",
      "     |  outlier scores of a datapoint from multiple HBOS instances using different\n",
      "     |  bin counts. \n",
      "     |  \n",
      "     |  HBOSAgg implements an adapted version of pyod's HBOS class, enabling the\n",
      "     |  use of dynamic bins. See HBOS_dynamic_bins for more information.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  instances : int, optional (default=100)\n",
      "     |      The number of HBOS instances to generate.\n",
      "     |  \n",
      "     |  dynamic_bins : bool, optional (default=True)\n",
      "     |      If True, the dynamic bin method is used.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  _arr_bin_counts : numpy.ndarray of shape (instances,)\n",
      "     |      Array of length instances with random bin counts between 2 and \n",
      "     |      sqrt(len(X)).\n",
      "     |  \n",
      "     |  results : dict\n",
      "     |      Dictionary containing the results of the HBOS instances. Keys are \n",
      "     |      'hbos_instance', 'bins', 'threshold', and 'decision_scores'.\n",
      "     |  \n",
      "     |  decision_scores_ : numpy.ndarray of shape (n_samples,)\n",
      "     |      The mean score for each sample.\n",
      "     |  \n",
      "     |  arr_rank : numpy.ndarray of shape (n_samples,)\n",
      "     |      The rank of the mean score for each sample.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, instances: int = 100, dynamic_bins: bool = True) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, X: numpy.ndarray)\n",
      "     |      Fit detector.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : numpy array of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted detector.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class HBOS_dynamic_bins(pyod.models.hbos.HBOS)\n",
      "     |  HBOS_dynamic_bins(dynamic_bins=True, **kwargs)\n",
      "     |  \n",
      "     |  Histogram-Based Outlier Score (HBOS) with dynamic bins.\n",
      "     |  \n",
      "     |  All bins in a histogram with dynamic bin contain the\n",
      "     |  same number of samples, and therefore have different bin widths. The area \n",
      "     |  of each bin is the same i.e. bin width * bin height remains constant. The \n",
      "     |  height of the bin is therefore the measure of the density of the space\n",
      "     |  within which a data point finds itself.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  dynamic_bins : bool, optional (default=True)\n",
      "     |      If True, the dynamic bin method is used.\n",
      "     |  \n",
      "     |  **kwargs : optional (default=None)\n",
      "     |      Other keyword arguments accepted by HBOS.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      HBOS_dynamic_bins\n",
      "     |      pyod.models.hbos.HBOS\n",
      "     |      pyod.models.base.BaseDetector\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dynamic_bins=True, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, X, y=None)\n",
      "     |      Fit detector. y is ignored in unsupervised methods.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : numpy array of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      y : Ignored\n",
      "     |          Not used, present for API consistency by convention.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted estimator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pyod.models.hbos.HBOS:\n",
      "     |  \n",
      "     |  decision_function(self, X)\n",
      "     |      Predict raw anomaly score of X using the fitted detector.\n",
      "     |      \n",
      "     |      The anomaly score of an input sample is computed based on different\n",
      "     |      detector algorithms. For consistency, outliers are assigned with\n",
      "     |      larger anomaly scores.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : numpy array of shape (n_samples, n_features)\n",
      "     |          The training input samples. Sparse matrices are accepted only\n",
      "     |          if they are supported by the base estimator.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      anomaly_scores : numpy array of shape (n_samples,)\n",
      "     |          The anomaly score of the input samples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pyod.models.base.BaseDetector:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      See http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html\n",
      "     |      and sklearn/base.py for more information.\n",
      "     |  \n",
      "     |  fit_predict(self, X, y=None)\n",
      "     |      Fit detector first and then predict whether a particular sample\n",
      "     |      is an outlier or not. y is ignored in unsupervised models.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : numpy array of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      y : Ignored\n",
      "     |          Not used, present for API consistency by convention.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      outlier_labels : numpy array of shape (n_samples,)\n",
      "     |          For each observation, tells whether\n",
      "     |          it should be considered as an outlier according to the\n",
      "     |          fitted model. 0 stands for inliers and 1 for outliers.\n",
      "     |      \n",
      "     |      .. deprecated:: 0.6.9\n",
      "     |        `fit_predict` will be removed in pyod 0.8.0.; it will be\n",
      "     |        replaced by calling `fit` function first and then accessing\n",
      "     |        `labels_` attribute for consistency.\n",
      "     |  \n",
      "     |  fit_predict_score(self, X, y, scoring='roc_auc_score')\n",
      "     |      Fit the detector, predict on samples, and evaluate the model by\n",
      "     |      predefined metrics, e.g., ROC.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : numpy array of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      y : Ignored\n",
      "     |          Not used, present for API consistency by convention.\n",
      "     |      \n",
      "     |      scoring : str, optional (default='roc_auc_score')\n",
      "     |          Evaluation metric:\n",
      "     |      \n",
      "     |          - 'roc_auc_score': ROC score\n",
      "     |          - 'prc_n_score': Precision @ rank n score\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |      \n",
      "     |      .. deprecated:: 0.6.9\n",
      "     |        `fit_predict_score` will be removed in pyod 0.8.0.; it will be\n",
      "     |        replaced by calling `fit` function first and then accessing\n",
      "     |        `labels_` attribute for consistency. Scoring could be done by\n",
      "     |        calling an evaluation method, e.g., AUC ROC.\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      See http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html\n",
      "     |      and sklearn/base.py for more information.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, optional (default=True)\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  predict(self, X, return_confidence=False)\n",
      "     |      Predict if a particular sample is an outlier or not.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : numpy array of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      return_confidence : boolean, optional(default=False)\n",
      "     |          If True, also return the confidence of prediction.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      outlier_labels : numpy array of shape (n_samples,)\n",
      "     |          For each observation, tells whether\n",
      "     |          it should be considered as an outlier according to the\n",
      "     |          fitted model. 0 stands for inliers and 1 for outliers.\n",
      "     |      confidence : numpy array of shape (n_samples,).\n",
      "     |          Only if return_confidence is set to True.\n",
      "     |  \n",
      "     |  predict_confidence(self, X)\n",
      "     |      Predict the model's confidence in making the same prediction\n",
      "     |      under slightly different training sets.\n",
      "     |      See :cite:`perini2020quantifying`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      -------\n",
      "     |      X : numpy array of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      confidence : numpy array of shape (n_samples,)\n",
      "     |          For each observation, tells how consistently the model would\n",
      "     |          make the same prediction if the training set was perturbed.\n",
      "     |          Return a probability, ranging in [0,1].\n",
      "     |  \n",
      "     |  predict_proba(self, X, method='linear', return_confidence=False)\n",
      "     |      Predict the probability of a sample being outlier. Two approaches\n",
      "     |      are possible:\n",
      "     |      \n",
      "     |      1. simply use Min-max conversion to linearly transform the outlier\n",
      "     |         scores into the range of [0,1]. The model must be\n",
      "     |         fitted first.\n",
      "     |      2. use unifying scores, see :cite:`kriegel2011interpreting`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : numpy array of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      method : str, optional (default='linear')\n",
      "     |          probability conversion method. It must be one of\n",
      "     |          'linear' or 'unify'.\n",
      "     |      \n",
      "     |      return_confidence : boolean, optional(default=False)\n",
      "     |          If True, also return the confidence of prediction.\n",
      "     |      \n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      outlier_probability : numpy array of shape (n_samples, n_classes)\n",
      "     |          For each observation, tells whether or not\n",
      "     |          it should be considered as an outlier according to the\n",
      "     |          fitted model. Return the outlier probability, ranging\n",
      "     |          in [0,1]. Note it depends on the number of classes, which is by\n",
      "     |          default 2 classes ([proba of normal, proba of outliers]).\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      See http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html\n",
      "     |      and sklearn/base.py for more information.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pyod.models.base.BaseDetector:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    Any = typing.Any\n",
      "        Special type indicating an unconstrained type.\n",
      "        \n",
      "        - Any is compatible with every type.\n",
      "        - Any assumed to have all methods.\n",
      "        - All values assumed to be instances of Any.\n",
      "        \n",
      "        Note that all the above statements are true from the point of view of\n",
      "        static type checkers. At runtime, Any should not be used with instance\n",
      "        or class checks.\n",
      "    \n",
      "    Generator = typing.Generator\n",
      "        A generic version of collections.abc.Generator.\n",
      "    \n",
      "    Type = typing.Type\n",
      "        A special construct usable to annotate class objects.\n",
      "        \n",
      "        For example, suppose we have the following classes::\n",
      "        \n",
      "          class User: ...  # Abstract base for User classes\n",
      "          class BasicUser(User): ...\n",
      "          class ProUser(User): ...\n",
      "          class TeamUser(User): ...\n",
      "        \n",
      "        And a function that takes a class argument that's a subclass of\n",
      "        User and returns an instance of the corresponding class::\n",
      "        \n",
      "          U = TypeVar('U', bound=User)\n",
      "          def new_user(user_class: Type[U]) -> U:\n",
      "              user = user_class()\n",
      "              # (Here we could write the user object to a database)\n",
      "              return user\n",
      "        \n",
      "          joe = new_user(BasicUser)\n",
      "        \n",
      "        At this point the type checker knows that joe has type BasicUser.\n",
      "\n",
      "FILE\n",
      "    c:\\users\\maxst\\desktop\\timeseriesoutlierdetection\\models\\hbosagg.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(models.HBOSagg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "479e59c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = HBOS_dynamic_bins(n_bins=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "885ce1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "824b71e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": " is set to 1. Not in the range of (2, inf).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\TimeSeriesOutlierDetection\\models\\HBOSagg.py:161\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    156\u001b[0m self._set_n_classes(y) \n\u001b[0;32m    158\u001b[0m _, n_features = X.shape[0], X.shape[1]\n\u001b[0;32m    160\u001b[0m if self.dynamic_bins:\n\u001b[1;32m--> 161\u001b[0m     # Check the number of bins\n\u001b[0;32m    162\u001b[0m     check_parameter(self.n_bins, low=2, high=np.inf)\n\u001b[0;32m    163\u001b[0m     self.hist_ = np.zeros([self.n_bins, n_features])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyod\\utils\\utility.py:102\u001b[0m, in \u001b[0;36mcheck_parameter\u001b[1;34m(param, low, high, param_name, include_left, include_right)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{param_name}\u001b[39;00m\u001b[38;5;124m is set to \u001b[39m\u001b[38;5;132;01m{param}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot in the range of (\u001b[39m\u001b[38;5;132;01m{low}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{high}\u001b[39;00m\u001b[38;5;124m].\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     98\u001b[0m             param\u001b[38;5;241m=\u001b[39mparam, low\u001b[38;5;241m=\u001b[39mlow, high\u001b[38;5;241m=\u001b[39mhigh, param_name\u001b[38;5;241m=\u001b[39mparam_name))\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m include_left \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m include_right) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    101\u001b[0m         param \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m low \u001b[38;5;129;01mor\u001b[39;00m param \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m high):\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{param_name}\u001b[39;00m\u001b[38;5;124m is set to \u001b[39m\u001b[38;5;132;01m{param}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot in the range of (\u001b[39m\u001b[38;5;132;01m{low}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{high}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    105\u001b[0m             param\u001b[38;5;241m=\u001b[39mparam, low\u001b[38;5;241m=\u001b[39mlow, high\u001b[38;5;241m=\u001b[39mhigh, param_name\u001b[38;5;241m=\u001b[39mparam_name))\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m:  is set to 1. Not in the range of (2, inf)."
     ]
    }
   ],
   "source": [
    "instance.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a31fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hbosagg = HBOSAgg(instances=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e370ec58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<models.HBOSagg.HBOSAgg at 0x14607daa0e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hbosagg.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82dca02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hbosagg.results['decision_scores'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e9fc5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6344596 , -0.2593887 , -0.37999713],\n",
       "       [-0.6248642 , -0.5198611 , -0.2142823 ],\n",
       "       [-0.15240793, -0.80282426, -0.4749724 ],\n",
       "       [-0.4928212 ,  0.00327428, -0.14373565],\n",
       "       [-0.60605574, -0.3516244 ,  0.03148587],\n",
       "       [-1.3169053 , -1.0963011 , -0.9429066 ],\n",
       "       [-0.67254835, -0.185792  , -0.6941734 ],\n",
       "       [-0.58890224, -0.09926583, -0.07410168],\n",
       "       [-1.5457591 , -0.33572602,  0.24307804],\n",
       "       [-1.1987883 , -1.0963011 , -0.9429066 ],\n",
       "       [-0.85237515, -0.8751287 , -0.5438074 ],\n",
       "       [-0.4204995 , -0.71552914, -1.1494849 ],\n",
       "       [-0.05203213, -0.08324881,  0.20518453],\n",
       "       [ 0.48897433, -0.1713338 , -0.03120727],\n",
       "       [ 0.42188582, -0.1713338 , -0.31161144],\n",
       "       [-0.8613529 , -0.16748929, -0.2960097 ],\n",
       "       [-0.8358578 , -0.5848206 , -1.2543465 ],\n",
       "       [-0.58006775, -0.54382104, -0.57754284],\n",
       "       [-1.9230678 , -1.1309595 , -0.5164442 ],\n",
       "       [ 0.15943548, -0.4435238 , -0.7327002 ],\n",
       "       [-1.5325003 , -1.0280776 , -1.3461139 ],\n",
       "       [-0.88467026, -0.94005215, -1.264048  ],\n",
       "       [-0.7525596 ,  0.28065592,  0.20354478],\n",
       "       [-0.4773713 , -1.2443677 , -0.4916315 ],\n",
       "       [-0.07602853, -0.6660739 , -0.40874687],\n",
       "       [-0.65456486, -1.1480876 , -1.0390387 ],\n",
       "       [-0.9229443 , -0.80282426,  0.1774528 ],\n",
       "       [-0.5389256 , -0.76895577, -0.7148506 ],\n",
       "       [-1.3086741 , -1.1291184 , -1.2089205 ],\n",
       "       [ 0.01818206, -0.51659715, -0.49065748],\n",
       "       [-1.2484169 , -0.6809732 , -0.7216833 ],\n",
       "       [-1.4364192 , -0.9255375 , -0.33538648],\n",
       "       [ 0.7380041 , -0.1713338 , -0.5704782 ],\n",
       "       [-0.8616371 , -0.32215768, -1.817898  ],\n",
       "       [-0.07602853, -0.6660739 , -0.46683392],\n",
       "       [-1.160611  , -0.51659715, -1.08716   ],\n",
       "       [-1.2984741 , -0.12648967, -1.0219114 ],\n",
       "       [-1.0722784 , -0.38915262,  0.14835879],\n",
       "       [-1.1922852 , -0.5213736 , -0.27410552],\n",
       "       [ 0.25312588,  0.12598754, -0.12460231],\n",
       "       [-0.20770216,  0.00327428, -0.14373565],\n",
       "       [-1.2531265 , -0.4285122 , -0.28312972],\n",
       "       [-0.9599037 , -0.6794607 , -1.0776685 ],\n",
       "       [-1.0867567 , -1.1775544 ,  0.09855429],\n",
       "       [-0.75558084, -0.58318055, -1.156567  ],\n",
       "       [-0.6051194 , -0.5732877 , -0.3670886 ],\n",
       "       [-0.0038905 , -0.1713338 , -0.41175896],\n",
       "       [-0.28162387, -0.37038442, -0.29619288],\n",
       "       [-0.847081  , -0.37038442, -0.31323957],\n",
       "       [-0.16125304, -0.37038442, -0.29619288],\n",
       "       [-1.222135  , -0.99189055, -1.5730143 ],\n",
       "       [-0.81097937, -0.96951884, -1.536597  ],\n",
       "       [ 0.51726484,  0.00327428, -1.0390387 ],\n",
       "       [-0.077943  , -0.62437415, -0.70035183],\n",
       "       [-0.2799527 , -0.58318055, -0.59961563],\n",
       "       [-0.14083505, -1.0963011 , -0.44920063],\n",
       "       [-0.08129682, -0.20596208, -0.8796322 ],\n",
       "       [-0.6248642 , -0.5198611 , -0.2142823 ],\n",
       "       [-2.242072  , -1.0553014 , -1.7546526 ],\n",
       "       [-0.8540082 , -0.99341923, -0.63680285],\n",
       "       [-1.0941093 , -0.32215768, -1.0219114 ],\n",
       "       [-0.43907723, -1.0262365 , -0.64186263],\n",
       "       [-0.43907723, -0.7171603 , -0.64186263],\n",
       "       [-2.1894994 , -1.3371539 , -2.089696  ],\n",
       "       [-0.6264481 , -0.33723852, -0.1819277 ],\n",
       "       [-1.6182556 , -0.36063045, -1.1790714 ],\n",
       "       [-0.3795588 , -0.531394  , -0.60628015],\n",
       "       [-0.32966208, -0.60312337, -1.1744744 ],\n",
       "       [-1.1467754 , -0.06460743, -0.31313697],\n",
       "       [-1.10067   , -0.73288727, -2.05265   ],\n",
       "       [-0.7238262 , -0.866637  , -0.19428478],\n",
       "       [-1.4267911 , -0.9285553 , -0.69661367],\n",
       "       [-0.8932886 , -0.58318055, -1.1790714 ],\n",
       "       [-0.3832265 , -0.4083421 ,  0.14136441],\n",
       "       [-1.0027872 , -0.96951884, -0.7517412 ],\n",
       "       [-0.8182521 , -0.99189055, -0.15880518],\n",
       "       [-1.1867232 , -0.94005215, -0.5003885 ],\n",
       "       [-0.49310178, -0.6809732 , -1.3721473 ],\n",
       "       [-0.6116176 ,  0.09652083, -0.01478026],\n",
       "       [-0.08129682, -0.77086914, -0.5770377 ],\n",
       "       [-0.32505828, -0.6126473 , -0.33107433],\n",
       "       [-1.4364192 , -0.9255375 , -0.4749724 ],\n",
       "       [-0.12992235, -0.4946102 , -0.74033195],\n",
       "       [-0.9386229 , -0.6794607 , -1.0731609 ],\n",
       "       [-0.9850318 ,  0.15794267,  0.582166  ],\n",
       "       [-0.4718411 , -0.06307873, -0.92058897],\n",
       "       [-0.85628647, -0.5897157 , -1.5056992 ],\n",
       "       [-1.107276  , -0.60312337, -1.1744744 ],\n",
       "       [-0.2958749 , -0.6146202 , -0.67561   ],\n",
       "       [ 0.56038207,  0.28065592,  0.17483692],\n",
       "       [ 0.32733694, -0.24062046, -0.35321972],\n",
       "       [ 0.14315422, -0.2593887 , -0.2404112 ],\n",
       "       [-0.6788103 , -0.77385086, -0.3879354 ],\n",
       "       [-1.3762014 , -0.78538376, -0.56692994],\n",
       "       [-0.42118335, -0.77385086, -0.6184412 ],\n",
       "       [-0.30916572, -0.6809732 , -1.4647807 ],\n",
       "       [-0.24035445, -0.39009717, -0.25426245],\n",
       "       [-0.18912451, -0.20214768, -0.32297385],\n",
       "       [-0.21323237, -1.1146038 , -0.5316117 ],\n",
       "       [ 0.97703695,  0.24599755, -0.33572614]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hbosagg.results['decision_scores'].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3c8012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python anomenv",
   "language": "python",
   "name": "anomenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
